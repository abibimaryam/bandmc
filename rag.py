# import os
# from langchain_chroma import Chroma
# from langchain.prompts import ChatPromptTemplate
# from langchain_community.llms.ollama import Ollama
# from embedding_functiom import embedding_function
# from config import CHROMA_PATH,model



# CHROMA_PATH = "chroma_db"

# PROMPT_TEMPLATE = """
# –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –Ω–∏–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç:

# {context}

# –í–æ–ø—Ä–æ—Å: {question}
# """

# def query_rag(query_text: str):
#     db = Chroma(
#         collection_name="meds",
#         persist_directory=CHROMA_PATH,
#         embedding_function=embedding_function()
#     )

#     print(f"üîç –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {db._collection.count()}")
#     print("üîé –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ...")
#     results = db.similarity_search_with_score(query_text, k=10)

#     print(f"\nüìÑ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n")
#     for i, (doc, score) in enumerate(results):
#         print(f"üîπ –î–æ–∫—É–º–µ–Ω—Ç {i+1} | –ù–∞–∑–≤–∞–Ω–∏–µ: {doc.metadata.get('—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} | Score: {score:.4f}")
#         print(doc.page_content[:300])
#         print("------")

#     if not results:
#         print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
#         return "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

#     context_text = "\n\n---\n\n".join([doc.page_content for doc, _ in results])
#     prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
#     prompt = prompt_template.format(context=context_text, question=query_text)

#     response_text = model.invoke(prompt)

#     sources = [doc.metadata.get("—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") for doc, _ in results]
#     print(f"\nüß† –û—Ç–≤–µ—Ç:\n{response_text}")
#     print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}")

#     return response_text


# def run_rag():
#     # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∞–∑—ã
#     if os.path.exists(CHROMA_PATH):
#         print("üìÅ –§–∞–π–ª—ã –≤ chroma_db:")
#         print(os.listdir(CHROMA_PATH))
#     else:
#         print(f"‚ùó –ü–∞–ø–∫–∞ {CHROMA_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")


#     # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
#     vectordb = Chroma(
#         collection_name="meds",
#         embedding_function=embedding_function(),
#         persist_directory=CHROMA_PATH,
#     )
#     print(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {vectordb._collection.count()}")

#     # –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
#     query_text = input("\n‚ùì –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å: ")
#     query_rag(query_text)


# if __name__ == "__main__":
#     run_rag()


import os
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_community.llms.ollama import Ollama
from embedding_functiom import embedding_function
from config import CHROMA_PATH, model


PROMPT_TEMPLATE = """
–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –Ω–∏–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç:

{context}

–í–æ–ø—Ä–æ—Å: {question}
"""

# üìå –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
def extract_key_entities(user_input: str) -> str:
    prompt = f"""
–ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, —Ç–∞–∫–∏–µ –∫–∞–∫:

- —Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–∞,
- –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ –Ω–µ–ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å),
- —Ñ–æ—Ä–º–∞ –≤—ã–ø—É—Å–∫–∞,
- –¥–æ–∑–∏—Ä–æ–≤–∫–∞,
- —Å—Ç—Ä–∞–Ω–∞-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å,
- —Ñ–∏—Ä–º–∞-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å,


–í–µ—Ä–Ω–∏ –∏—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é ‚Äî –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–µ—Ä–Ω–∏ "None".

–ó–∞–ø—Ä–æ—Å: "{user_input}"
"""
    response = model.invoke(prompt).strip()
    print(response)
    return response if response.lower() != "none" else None


def query_rag(user_input: str):
    key_phrases = extract_key_entities(user_input)
    if not key_phrases:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±—â–∏–π –ø–æ–∏—Å–∫.")
        query_text = user_input
    else:
        print(f"üß∑ –ò–∑–≤–ª–µ—á–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã: {key_phrases}")
        query_text = key_phrases

    db = Chroma(
        collection_name="meds",
        persist_directory=CHROMA_PATH,
        embedding_function=embedding_function()
    )

    print(f"üîç –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {db._collection.count()}")
    print("üîé –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ...")
    results = db.similarity_search_with_score(query_text, k=20)

    if not results:
        print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

    print(f"\nüìÑ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n")
    for i, (doc, score) in enumerate(results):
        print(f"üîπ –î–æ–∫—É–º–µ–Ω—Ç {i+1} | –ù–∞–∑–≤–∞–Ω–∏–µ: {doc.metadata.get('—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} | Score: {score:.4f}")
        print(doc.page_content[:300])
        print("------")

    context_text = "\n\n---\n\n".join([doc.page_content for doc, _ in results])
    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    prompt = prompt_template.format(context=context_text, question=user_input)

    response_text = model.invoke(prompt)

    sources = [doc.metadata.get("—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") for doc, _ in results]
    print(f"\nüß† –û—Ç–≤–µ—Ç:\n{response_text}")
    print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}")

    return response_text


def run_rag():
    if os.path.exists(CHROMA_PATH):
        print("üìÅ –§–∞–π–ª—ã –≤ chroma_db:")
        print(os.listdir(CHROMA_PATH))
    else:
        print(f"‚ùó –ü–∞–ø–∫–∞ {CHROMA_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

    vectordb = Chroma(
        collection_name="meds",
        embedding_function=embedding_function(),
        persist_directory=CHROMA_PATH,
    )
    print(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {vectordb._collection.count()}")

    query_text = input("\n‚ùì –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å: ")
    query_rag(query_text)


if __name__ == "__main__":
    run_rag()
