import os
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_community.llms.ollama import Ollama
from embedding_functiom import embedding_function
from config import CHROMA_PATH,model



CHROMA_PATH = CHROMA_PATH

PROMPT_TEMPLATE = """
–í—ã ‚Äî —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏ –Ω–∞–π–¥–∏—Ç–µ –í–°–ï –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–º –Ω–∏–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. 
–£–∫–∞–∂–∏—Ç–µ, –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ —á–∞—Å—Ç–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç —Ñ–∞–∫—Ç–∞–º, –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. 
–ï—Å–ª–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç—É ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏—Ç–µ: "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[—Å–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∏–ª–∏ "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."]

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: {question}
"""


def query_rag(query_text: str):
    db = Chroma(
        collection_name="meds",
        persist_directory=CHROMA_PATH,
        embedding_function=embedding_function()
    )

    print(f"üîç –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {db._collection.count()}")
    print("üîé –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ...")
    results = db.similarity_search_with_score(query_text, k=10)

    print(f"\nüìÑ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n")
    for i, (doc, score) in enumerate(results):
        print(f"üîπ –î–æ–∫—É–º–µ–Ω—Ç {i+1} | –ù–∞–∑–≤–∞–Ω–∏–µ: {doc.metadata.get('—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} | Score: {score:.4f}")
        print(doc.page_content[:300])
        print("------")

    if not results:
        print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

    context_text = "\n\n---\n\n".join([doc.page_content for doc, _ in results])
    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    prompt = prompt_template.format(context=context_text, question=query_text)

    response_text = model.invoke(prompt)

    sources = [doc.metadata.get("—Ç–æ—Ä–≥–æ–≤–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ") for doc, _ in results]
    print(f"\nüß† –û—Ç–≤–µ—Ç:\n{response_text}")
    print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}")

    return response_text


def run_rag():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∞–∑—ã
    if os.path.exists(CHROMA_PATH):
        print("üìÅ –§–∞–π–ª—ã –≤ chroma_db:")
        print(os.listdir(CHROMA_PATH))
    else:
        print(f"‚ùó –ü–∞–ø–∫–∞ {CHROMA_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")


    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    vectordb = Chroma(
        collection_name="meds",
        embedding_function=embedding_function(),
        persist_directory=CHROMA_PATH,
    )
    print(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {vectordb._collection.count()}")

    # –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    query_text = input("\n‚ùì –í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: ")
    query_rag(query_text)


if __name__ == "__main__":
    run_rag()

